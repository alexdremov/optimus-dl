defaults:
  - tokenizer: gpt2


dataset:
  repo_id: "roneneldan/TinyStories"
  split: "train"
  cache_dir: ${oc.env:SCRATCH_HOME,.}/cache
  file_pattern: null

processing:
  shard_size_mb: 256
  shuffle_buffer_size: 32000
  text_column: "text"
  seed: 42
  dtype: "uint16"
  num_proc: ${cpu_count:}

output:
  dir: ${oc.env:SCRATCH_HOME,./outputs/}/data/${dataset.repo_id}/${dataset.split}
  name: "shard"
